# UE4 内存管理

UE4拥有自己的内存管理器，使之能够独立管理、加速、跟踪内存，并内存对齐以支持多个平台。

![img](https://img2020.cnblogs.com/blog/78946/202104/78946-20210405155329825-609161482.png)

## OS级内存分配API

- Windows

  ```C++
  LPVOID WINAPI VirtualAlloc(...);
  BOOL WINAPI VirtualFree(...);
  ```

- Unix及Mac

  ```c++
  void* mmap(...)
  bool  munmap(...)
  ```

## FMalloc(内存分配器)

> FMalloc的定义位于UnrealEngine\Engine\Source\Runtime\Core\Public\HAL\MemoryBase.h

#### 基类

- FUseSystemMallocForNew：重载了类的new、delete运算符，避免使用new FMalloc出现递归分配的问题。
- FExec：用于处理控制台指令。

#### 通用接口

- `void* Malloc( SIZE_T, uint32 Alignment=DEFAULT_ALIGNMENT )`：内存分配函数
- `void* TryMalloc( SIZE_T Count, uint32 Alignment=DEFAULT_ALIGNMENT )`：与Malloc不同的是，分配失败可能返回`nullptr`
- `void* Realloc( void* Original, SIZE_T Count, uint32 Alignment=DEFAULT_ALIGNMENT )`：重分配函数
- `void* TryRealloc(void* Original, SIZE_T Count, uint32 Alignment=DEFAULT_ALIGNMENT)`：与Realloc不同的是，分配失败可能返回`nullptr`，并且Original所指向的内存将仍然有效
- `void Free( void* Original ) `：内存销毁函数
- `SIZE_T QuantizeSize(SIZE_T Count, uint32 Alignment)`：对于某些分配器来说，这将返回应该被请求消除内部碎片的实际大小。 返回值总是>= Count。 这可以用来扩大和缩小容器到最佳尺寸。 这个调用总是快速且线程安全的，没有锁。  
- `bool GetAllocationSize(void *Original, SIZE_T &SizeOut)`：给定地址分配的内存大小 。
- `void Trim(bool bTrimThreadCaches)`：尽可能多释放内存。 必须从主线程调用。  
- `void SetupTLSCachesOnCurrentThread()`：在当前线程上设置TLS缓存。
- `void ClearAndDisableTLSCachesOnCurrentThread()`：清除当前线程上的TLS缓存，并禁用任何未来的缓存。  
- `bool IsInternallyThreadSafe() const `：用于说明该分配器是否是线程安全，如果不是线程安全，可能会采用其他内存分配器
- `bool ValidateHeap()：`验证堆分配器

#### 分配器类型

FMalloc的子类通过实现上述接口，直接操作OS级别的内存分配API，完成不同的分配策略，其中主要有：

> UnrealEngine\Engine\Source\Runtime\Core\Private\HAL文件下以Malloc开头的文件

- **Ansi**：标准的c分配器，直接调用malloc、free、realloc。

  > 对于windows平台，启用了[低碎片堆](https://docs.microsoft.com/en-us/windows/win32/memory/low-fragmentation-heap?redirectedfrom=MSDN)功能

- **Stomp**：有助于追踪分配过程中读写造成的问题，如野指针，内存越界等。

  > Stomp 在释放物理内存的同时保留了虚拟地址范围。释放内存后在其他地方使用相同的指针，则会抛出异常。因此当你想跟踪一些问题时，它可能会有效，但它同样具有副作用，关联虚拟地址和物理地址的OS页表会消耗大量内存。

- **TBB**：Thread Building Blocks，Intel提供的64位可伸缩内存分配器

  > **英特尔® 线程构建模块 | 英特尔® 软件** https://software.intel.com/en-us/tbb

- **Jemalloc**：主要用于 Unix 的内存分配器。

  >**jemalloc** http://jemalloc.net/
  >**jemalloc / jemalloc** https://github.com/jemalloc/jemalloc

- **Binned**：装箱内存分配器，主要用于IOS。

  - **Binned**：

    > 装箱分配器将一块内存（**Pool**）划分为许多不同大小的槽位，比如Binned在PC上把64KB划分成41个不同的槽位，从尾部往前分配空闲槽位：
    >
    > ```
    > static const uint32 BlockSizes[POOL_COUNT] = {
    > 	16,		32,		48,		64,		80,		96,		112,	128,
    > 	160,	192,	224,	256,	288,	320,	384,	448,
    > 	512,	576,	640,	704,	768,	896,	1024,	1168,
    > 	1360,	1632,	2048,	2336,	2720,	3264,	4096,	4672,
    > 	5456,	6544,	8192,	9360,	10912,	13104,	16384,	21840,	32768
    > };
    > ```

  - **Binned2**：Binned2分配器支持线程本地内存分配，不需要每次都加锁。这在频繁小块内存分配、释放时可以提升不少性能。

  - **Binned3**：使用虚拟内存地址（逻辑内存地址），可以通过排列它来高速执行Pool的Index搜索，以便可以从内存的指针计算出目标大小的Pool 。

- **Mimalloc**：一个优于 tcmalloc 和 jemalloc 的通用内存分配器

  > Github https://github.com/microsoft/mimalloc
  >
  > MS Research https://www.microsoft.com/en-us/research/publication/mimalloc-free-list-sharding-in-action/

#### 不同平台对内存分配器的支持情况

|              | **Ansi** | **TBB**® | **Jemalloc**® | **Binned** | **Binned2** | **Binned3** | **Mimalloc**® | **Stomp** |
| :----------: | :------: | :------: | :-----------: | :--------: | :---------: | :---------: | :-----------: | :-------: |
| **Android**  |    √     |          |               |     √      |   default   | √（64bits） |               |           |
|   **IOS**    |    √     |          |               |  default   |             |             |               |           |
| **Windows**  |    √     | defalut  |               |     √      |      √      | √（64bits） |       √       |     √     |
|  **Linux**   |    √     |          |       √       |     √      |   default   |             |               |     √     |
|   **Mac**    |    √     | default  |               |     √      |      √      |             |               |     √     |
| **HoloLens** |    √     |          |               |            |             |   default   |               |           |

## FGenericPlatformMemory（平台内存管理类）

>UnrealEngine\Engine\Source\Runtime\Core\Public\GenericPlatform\GenericPlatformMemory.h

不同平台都有对应的平台内存管理类，它们继承自FGenericPlatformMemory，存储着平台相关的内存信息，并提供函数接口BaseAllocator()创建内存分配器

#### 平台实现

- FAndroidPlatformMemory
- FApplePlatformMemory
- FIOSPlatformMemory
- FWindowsPlatformMemory
- FLinuxPlatformMemory
- FUnixPlatformMemory
- FMacPlatformMemory

#### BaseAllocator

各个平台通过实现`static FMalloc* FGenericPlatformMemory::BaseAllocator()`，创建平台相应的FMalloc类型，

> 以**Windows**为例，其实现位于`UnrealEngine\Engine\Source\Runtime\Core\Public\Windows\WindowsPlatformMemory.h`

## 应用层

#### FMemory（内存管理接口）

**FMemory**用于对**FMalloc**的全局实例**(GMalloc)**和**FGenericPlatformMemory**的接口进行封装，提供一系列供用户直接使用的静态函数来操纵内存，包括但不限于：`Malloc`、`Realloc`、`Free`、`Memmove`、`Memcmp`、`Memset`、`Memcpy`...

#### new delete（全局运算符重写）

`UnrealEngine\Engine\Source\Runtime\Core\Public\Modules\Boilerplate\ModuleBoilerplate.h`中对全局new delete进行重写，使之转接到FMemory::Malloc，样例如下

```c++
void* operator new[]( size_t Size) OPERATOR_NEW_THROW_SPEC { return FMemory::Malloc( Size ? Size : 1 ); } 
```

#### Allocator（分配代理）

> UnrealEngine\Engine\Source\Runtime\Core\Public\Containers\ContainerAllocationPolicies.h

之前称FMalloc为内存分配器，而Allocator的职责则偏向于分配策略。UE中具有以下的分配策略：

- **TAlignedHeapAllocator\<Aligment>**：依据对齐的堆栈分配代理
- **TSizedHeapAllocator\<IndexSize>**：依据size的堆栈分配代理
- **TInlineAllocator\<NumInlineElements, SecondaryAllocator >**：超出最大元素数量的部分会使用次级分配代理进行分配。

- **TNonRelocatableInlineAllocator\<NumInlineElements>**：允许存储指向其内联元素的指针，其次级堆分配代理可实现TInlineAllocator。
- **TFixedAllocator\<NumInlineElements>**：固定分配代理在同一次分配中最多分配指定数量的元素，与内联分配代理不同的是，超出部分不使用次级分配。  
- **TSparseArrayAllocator\<InElementAllocator,InBitArrayAllocator>**：单一类型的稀疏数组分配代理
- **TInlineSparseArrayAllocator<NumInlineElements, SecondaryAllocator> **：允许对一组元素的内联分配大小进行调整的稀疏数组分配代理
- **TFixedSparseArrayAllocator\<NumInlineElements>**：与inline分配器不同的是，它不支持次级分配代理
- **TSetAllocator<···>**：单一类型的集合分配代理
- **TInlineSetAllocator<···>**：允许指定内联分配大小和次级分配
- **TFixedSetAllocator<···>**：只允许指定内联分配大小

#### UE4容器

> UnrealEngine\Engine\Source\Runtime\Core\Public\Containers\ContainersFwd.h

- **TArray**：TSizedHeapAllocator<32>
- **TArray64**：TSizedHeapAllocator<64>
- **TSet**：TSetAllocator<>
- **TMap**：TSetAllocator<>
- **TMultiMap**：TSetAllocator<>
- **TSortedMap**：TSizedHeapAllocator<32>
- **FString**：内含TArray\<TCHAR>
- **TByteArray、 TConstSetBitIterator、TConstDualSetBitIterator、TScriptBitArray**：TInlineAllocator<4>  
- **TSparseArray、FScriptSparseArray **：TSparseArrayAllocator<>

#### UObject

UE4为UObject使用了特定的内存分配策略**FUObjectAllocator**，其中提供了以下接口：

> UnrealEngine\Engine\Source\Runtime\CoreUObject\Public\UObject\UObjectAllocator.h

```C++
/**
* Allocates a UObjectBase from the free store or the permanent object pool
*
* @param Size size of uobject to allocate
* @param Alignment alignment of uobject to allocate
* @param bAllowPermanent if true, allow allocation in the permanent object pool, if it fits
* @return newly allocated UObjectBase (not really a UObjectBase yet, no constructor like thing has been called).
*/
UObjectBase* AllocateUObject(int32 Size, int32 Alignment, bool bAllowPermanent);

/**
* Returns a UObjectBase to the free store, unless it is in the permanent object pool
*
* @param Object object to free
*/
void FreeUObject(UObjectBase *Object) const;
```

全局实例**GUObjectAllocator**，在`UnrealEngine\Engine\Source\Runtime\CoreUObject\Private\UObject\.Class.cpp`中使用该实例创建以及销毁**UObejct**

## 开源内存分配框架

### [mimalloc](https://github.com/microsoft/mimalloc)

mimalloc是一种通用分配器，具有出色的[性能](https://github.com/microsoft/mimalloc#performance)特征。最初由 Daan Leijen 为[Koka](https://koka-lang.github.io/)和[Lean](https://github.com/leanprover/lean)语言的运行时系统开发 。

#### 优势

- **小而一致**：该库使用简单且一致的数据结构，大约有 8k LOC。这使得它非常适合集成和适应其他项目。对于运行时系统，它提供了用于单调*心跳*和延迟释放的钩子（对于具有引用计数的有界最坏情况时间）。
- **空闲列表分片**：每个“mimalloc 页”有许多较小的列表，而不是一个大的空闲列表（每个大小类），这减少了碎片并增加了局部性——及时分配的东西在内存中分配得很近。（一个 mimalloc 页包含一个大小级别的块，在 64 位系统上通常是 64KiB）。
- **自由列表多分片**：好主意！我们不仅将每个 mimalloc 页面的空闲列表分片，而且对于每个页面，我们都有多个空闲列表。特别是，有一个用于线程本地`free`操作的列表，另一个用于并发`free` 操作。从另一个线程中释放现在可以是单个 CAS，而无需线程之间的复杂协调。由于将有数千个单独的空闲列表，争用自然分布在堆上，并且在单个位置上竞争的机会将很低——这与跳过列表等随机算法非常相似，其中添加随机预言机消除了需要对于更复杂的算法。
- **急切页面重置**：当“页面”变空时（由于空闲列表分片的机会增加），内存被标记为操作系统未使用（“重置”或“清除”）减少（真实）内存压力和碎片，特别是在长时间运行的程序。
- **安全**: *mimalloc*可以在安全模式下构建，添加保护页、随机分配、加密空闲列表等，以防止各种堆漏洞。性能损失通常比我们的基准平均高出 10% 左右。
- **一流的堆**：有效地创建和使用多个堆来跨不同区域进行分配。堆可以一次销毁，而不是单独释放每个对象。
- **有界**：它不会受到*膨胀* 的影响，有界最坏情况分配时间 ( *wcat* )，有界空间开销（约 0.2% 元数据，分配大小最多浪费 12.5%），并且没有内部点仅使用原子操作的争用。
- **快速**：在我们的基准测试中， *mimalloc*优于其他领先的分配器（*jemalloc*、*tcmalloc*、*Hoard*等），并且通常使用更少的内存。一个不错的特性是它在广泛的基准测试中始终表现良好。对于较大的服务器程序，也有很好的巨大操作系统页面支持。

### [oneTBB](https://www.intel.com/content/www/us/en/developer/tools/oneapi/onetbb.html)

英特尔® oneAPI 线程构建块 (oneTBB) 是一个灵活的性能库，即使您不是线程专家，也可以简化为跨加速架构的复杂应用程序添加并行性的工作。

#### 特征

- **指定逻辑性能，而不是线程**
  运行时库自动将逻辑并行映射到线程上，从而最有效地利用处理器资源。
- **以线程为目标提高性能**
  专注于并行化计算密集型工作的特定目标，提供更高级别、更简单的解决方案。
- **与其他线程包共存  **
  它能够与其他线程无缝兼容，使您可以灵活地保持旧代码不变，并使用 oneTBB 进行新的实现。
- **强调可扩展的数据并行编程**
  oneTBB 强调数据并行编程，而不是将程序分解成功能块并为每个功能块分配一个单独的线程，从而使多个线程能够在集合的不同部分上工作。通过将集合分成更小的部分，这可以很好地扩展到更多的处理器。随着您添加处理器和加速器，程序性能会提高。

### [jemalloc](https://github.com/jemalloc/jemalloc)

jemalloc 是一个通用的`malloc(3)`实现，它强调避免碎片化和可扩展的并发支持。它旨在用作系统提供的内存分配器，如在 FreeBSD 的 libc 库中，以及用于链接到 C/C++ 应用程序。jemalloc 提供了许多超出标准分配器功能的内省、内存管理和调整功能。

### [tcmalloc](https://github.com/google/tcmalloc)

TCMalloc 是 Google 对 C`malloc()`和 C++ 的自定义实现，`operator new`用于C 和 C++ 代码中的分配内存。此自定义内存分配框架是 C 标准库（在 Linux 上通常通过`glibc`）和 C++ 标准库提供框架的替代方案。

#### 优势

- 性能随应用程序的并行程度提升
- 依附于C++14 和 C++17 进行了优化，并且在保证性能优势的情况下与标准略有不同（这些在[TCMalloc 参考](https://github.com/google/tcmalloc/blob/master/docs/reference.md)中注明）
- 允许在某些架构下提高性能的扩展，以及其他行为，例如指标收集

#### 特性

- 通过管理特定大小的内存块（称为“页面”）从操作系统执行分配。
- 将单独的页面（或在 TCMalloc 中称为“跨度”的页面运行）用于特定的对象大小。例如，所有 16 字节的对象都放置在专门为该大小的对象分配的“跨度”中。在这种情况下获取或释放内存的操作要简单得多。
- 将内存保存在*缓存中*以加快对常用对象的访问。如果以后重新分配此类内存，即使在释放后保留此类缓存也有助于避免代价高昂的系统调用。

## 如何应用

![](./src/UE4内存体系.png)

### Malloc的选择

UE程序在不同平台具有唯一的底层内存分配器，其中PC端默认使用oneTBB，移动端是UE内置的Binned分配器，由于要实现一套完整的内存分配框架需要投入大量的人力与精力，所以摆在我们面前的其实只有一条路——开源库。

在[mimalloc](https://github.com/microsoft/mimalloc)的基准测试中，它的各项性能指数在大多数情况下比[jemalloc](https://github.com/jemalloc/jemalloc) 和 [tcmalloc ](https://github.com/google/tcmalloc)更为优越，它是一个不错的选择。

在C++17的基础上，想要应用及替换一套内存分配框架是很容易的事情——只需覆盖operator new/delete。

下面是应用mimalloc的例子：

```C++
#include <vcruntime_new.h>

_NODISCARD _Ret_notnull_ _Post_writable_byte_size_(_Size) _VCRT_ALLOCATOR
void* __CRTDECL  operator new  (size_t Size) { return mi_malloc(Size ? Size : 1); }

_NODISCARD _Ret_notnull_ _Post_writable_byte_size_(_Size) _VCRT_ALLOCATOR
void* __CRTDECL operator new[](size_t Size) { return mi_malloc(Size ? Size : 1); }

_NODISCARD _Ret_maybenull_ _Success_(return != NULL) _Post_writable_byte_size_(_Size) _VCRT_ALLOCATOR
void* __CRTDECL operator new  (size_t Size, const std::nothrow_t&) { return mi_malloc(Size ? Size : 1); }

_NODISCARD _Ret_maybenull_ _Success_(return != NULL) _Post_writable_byte_size_(_Size) _VCRT_ALLOCATOR
void* __CRTDECL operator new[](size_t Size, const std::nothrow_t&) { return mi_malloc(Size ? Size : 1); }

void __CRTDECL operator delete  (void* Ptr) { mi_free(Ptr); }
void __CRTDECL operator delete[](void* Ptr) { mi_free(Ptr); }
void __CRTDECL operator delete  (void* Ptr, const std::nothrow_t&) { mi_free(Ptr); }
void __CRTDECL operator delete[](void* Ptr, const std::nothrow_t&) { mi_free(Ptr); }
void __CRTDECL operator delete  (void* Ptr, size_t Size) { mi_free(Ptr); }
void __CRTDECL operator delete[](void* Ptr, size_t Size) { mi_free(Ptr); }
void __CRTDECL operator delete  (void* Ptr, size_t Size, const std::nothrow_t&) { mi_free(Ptr); }
void __CRTDECL operator delete[](void* Ptr, size_t Size, const std::nothrow_t&) { mi_free(Ptr); }

_NODISCARD _Ret_notnull_ _Post_writable_byte_size_(_Size) _VCRT_ALLOCATOR
void* __CRTDECL operator new  (size_t Size, std::align_val_t Alignment) { return mi_malloc_aligned(Size ? Size : 1, (std::size_t)Alignment); }

_NODISCARD _Ret_notnull_ _Post_writable_byte_size_(_Size) _VCRT_ALLOCATOR
void* __CRTDECL operator new[](size_t Size, std::align_val_t Alignment) { return mi_malloc_aligned(Size ? Size : 1, (std::size_t)Alignment); }

_NODISCARD _Ret_maybenull_ _Success_(return != NULL) _Post_writable_byte_size_(_Size) _VCRT_ALLOCATOR
void* __CRTDECL operator new  (size_t Size, std::align_val_t Alignment, const std::nothrow_t&) { return mi_malloc_aligned(Size ? Size : 1, (std::size_t)Alignment); }

_NODISCARD _Ret_maybenull_ _Success_(return != NULL) _Post_writable_byte_size_(_Size) _VCRT_ALLOCATOR
void* __CRTDECL operator new[](size_t Size, std::align_val_t Alignment, const std::nothrow_t&) { return mi_malloc_aligned(Size ? Size : 1, (std::size_t)Alignment); }

void __CRTDECL operator delete  (void* Ptr, std::align_val_t Alignment) { mi_free(Ptr); }
void __CRTDECL operator delete[](void* Ptr, std::align_val_t Alignment) { mi_free(Ptr); }
void __CRTDECL operator delete  (void* Ptr, std::align_val_t Alignment, const std::nothrow_t&) { mi_free(Ptr); }
void __CRTDECL operator delete[](void* Ptr, std::align_val_t Alignment, const std::nothrow_t&) { mi_free(Ptr); }
void __CRTDECL operator delete  (void* Ptr, size_t Size, std::align_val_t Alignment) { mi_free(Ptr); }
void __CRTDECL operator delete[](void* Ptr, size_t Size, std::align_val_t Alignment) { mi_free(Ptr); }
void __CRTDECL operator delete  (void* Ptr, size_t Size, std::align_val_t Alignment, const std::nothrow_t&) { mi_free(Ptr); }
void __CRTDECL operator delete[](void* Ptr, size_t Size, std::align_val_t Alignment, const std::nothrow_t&) { mi_free(Ptr); }
```

### Allocator的选择

#### [EASTL]()

EASTL（EA 标准模板库）旨在成为一个模板库，它包含并扩展C++ STL 的 功能，同时对很多游戏开发有用的方式进行了改进，并强调性能高于一切。EASTL 的大部分设计与标准 STL 相同，与标准STL实现不同的主要领域基本如下：

- EASTL 具有简化且更灵活的自定义分配方案。
- EASTL 的代码更易于阅读。
- EASTL 有扩展容器和算法。
- EASTL 具有专为游戏开发而设计的优化。

在上述各项中，唯一与 STL 不兼容的区别是内存分配的情况。

#### [foonathan](https://github.com/foonathan/memory)

foonathan也是为了解决STL存在的缺陷，但与EASTL不同，它并没有尝试更改 STL。

#### [STL C++17 polymorphic memory source](https://www.rkaiser.de/wp-content/uploads/2021/03/embo2021-pmr-STL-for-Embedded-Applications-en.pdf)

在C++17以前，完成STL容器的内存分配需要借助allocator，它主要有以下缺陷：

- allocator是模板签名的一部分，不同allocator的容器，无法混用

  ```c++
  vector<int,allocator0> v0;
  vector<int,allocator1> v1;
  v0 = v1; 	//Error
  ```

- allocator内存对齐无法控制，需要传入自定义allocator

- allocator没有内部状态

C++17中为容器提供了新的内存分配方法 ——` <memory_resource>`

它的用法就像是下面这样：

```C++
#include <memory_resource>
#include <vector>
#include <string>            
#include <iostream>

class CustomMemoryResource :public std::pmr::memory_resource{		//自定义memory_source
public:
    CustomMemoryResource() {}
private:
    virtual void* do_allocate(const size_t _Bytes, const size_t _Align) override {
        return ::operator new(_Bytes,std::align_val_t(_Align));
    }                                                                                                                                             
    virtual void do_deallocate(void* _Ptr, size_t _Bytes, size_t _Align){
        ::operator delete(_Ptr,_Bytes, std::align_val_t(_Align));
    };
    virtual bool do_is_equal(const memory_resource& _That) const noexcept {
        return this==&_That;
    };
};
int main() {
    std::pmr::unsynchronized_pool_resource ms1; //非线程安全的池分配器
    std::pmr::synchronized_pool_resource ms2;   //同步池分配器
    CustomMemoryResource custom_memory_source;  //自定义分配器
    char buffer[20];
    std::pmr::monotonic_buffer_resource mbr(std::data(buffer),std::size(buffer),&custom_memory_source);   //单调缓存分配器，从buffer中分配内存，直到调用mbr.release()内存才会释放，超出缓存会使用上级分配器进行分配
    {
        std::pmr::vector<std::pmr::string> vec{ &mbr };
        vec.push_back("Hello World");
        vec.push_back("One Two Three");
    }   //vec 的内存不会释放
    mbr.release();  //此时才会释放mbr中的内存
}
```

从上面的代码可以看出**MemoryResouce**完美解决了**allocator**存在的问题，我们只需使用来自于命名空间`std::pmr`的容器。

它是怎么做到的呢？

以`std::pmr::vector`为例，找到它的定义：

```C++
namespace pmr {
    template <class _Ty>
    using vector = std::vector<_Ty, polymorphic_allocator<_Ty>>;
} // namespace pmr
```

非常简单，它只是一个使用了`polymorphic_allocator`的`std::vector`，找到它定义，可以发现如下代码：

```C++
template <class _Ty>
class polymorphic_allocator {
public:
    //...
    _NODISCARD __declspec(allocator) _Ty* allocate(_CRT_GUARDOVERFLOW const size_t _Count) {
        // get space for _Count objects of type _Ty from _Resource
        void* const _Vp = _Resource->allocate(_Get_size_of_n<sizeof(_Ty)>(_Count), alignof(_Ty));
        return static_cast<_Ty*>(_Vp);
    }

    void deallocate(_Ty* const _Ptr, const size_t _Count) noexcept /* strengthened */ {
        // return space for _Count objects of type _Ty to _Resource
        // No need to verify that size_t can represent the size of _Ty[_Count].
        _Resource->deallocate(_Ptr, _Count * sizeof(_Ty), alignof(_Ty));
        
private:
    memory_resource* _Resource = _STD pmr::get_default_resource();    
};
```

不难发现它其实只是在原来的Allocator接口上调用memory_resource的方法。

#### UE中的Allocator

UE的Allocator主要有三种分配模式：

- HeapAllocator：堆分配器，直接调用FMemory从堆上分配内存，其简化代码如下：

  ```C++
  class HeapAllocator{
  	FORCEINLINE ~ForAnyElementType(){
  		if(Data)
  			FMemory::Free(Data);
  	}
      
      FORCEINLINE FScriptContainerElement* GetAllocation() const{
          return Data;
      }
          
  	FORCEINLINE void ResizeAllocation(SizeType PreviousNumElements, SizeType NumElements, SIZE_T NumBytesPerElement){
          if (Data || NumElements){
  
              Data = (FScriptContainerElement*)FMemory::Realloc( Data, NumElements*NumBytesPerElement );
          }
      }
  	FScriptContainerElement* Data;
  };
  ```

- FixedAllocator：定长分配器，通过模板参数设置好固定长度的InlineData，之后就一直使用这块内存，简化代码如下

  ```C++
  template <uint32 NumInlineElements>
  class TFixedAllocator{
      FORCEINLINE ElementType* GetAllocation() const{
  		return  InlineData;
  	}
      void ResizeAllocation(SizeType PreviousNumElements, SizeType NumElements,SIZE_T NumBytesPerElement){
          check(NumElements <= NumInlineElements);
      }
      TTypeCompatibleBytes<ElementType> InlineData[NumInlineElements];
  };
  ```

  

- InlineAllocator：内联分配器，定长分配器的扩展版本，当分配大小超出内联大小时，会使用次级分配器进行分配

```C++
template <uint32 NumInlineElements,typename SecondaryAllocator = FDefaultAllocator>
class TInlineAllocator{
    FORCEINLINE ElementType* GetAllocation() const{
		return IfAThenAElseB<ElementType>(SecondaryData.GetAllocation(),GetInlineElements());
	}
    void ResizeAllocation(SizeType PreviousNumElements, SizeType NumElements,SIZE_T NumBytesPerElement){
        if(NumElements <= NumInlineElements){
            if(SecondaryData.GetAllocation()){
                RelocateConstructItems<ElementType>((void*)InlineData, (ElementType*)SecondaryData.GetAllocation(), PreviousNumElements);
                SecondaryData.ResizeAllocation(0,0,NumBytesPerElement);
            }
        }
        else {
            if(!SecondaryData.GetAllocation()){
                // Allocate new indirect memory for the data.
                SecondaryData.ResizeAllocation(0,NumElements,NumBytesPerElement);

                // Move the data out of the inline data area into the new allocation.
                RelocateConstructItems<ElementType>((void*)SecondaryData.GetAllocation(), GetInlineElements(), PreviousNumElements);
            }
            else{
                // Reallocate the indirect data for the new size.
                SecondaryData.ResizeAllocation(PreviousNumElements, NumElements, NumBytesPerElement);
            }
        }
    }
    TTypeCompatibleBytes<ElementType> InlineData[NumInlineElements];
    SecondaryAllocator<ElementType> SecondaryData;
};
```

#### STL Allocator

```C++
template <class T>
struct HeapAllocator {
	typedef T value_type;
	HeapAllocator() = default;
	template <class U> constexpr HeapAllocator(const HeapAllocator <U>&)  {}
	T* allocate(std::size_t size) {
		if (size > std::numeric_limits<std::size_t>::max() / sizeof(T))
			throw std::bad_array_new_length();
		T* Data = static_cast<T*>(operator new(sizeof(T) * size, (std::align_val_t)alignof(T)));
		if (Data)
			return Data;
		throw std::bad_alloc();
	}
	void deallocate(T* Data, std::size_t size) noexcept {
		operator delete(Data, size, (std::align_val_t)alignof(T));
	}
};


template <class T, size_t InlineSize>
struct FixedAllocator {
	typedef T value_type;
	FixedAllocator() = default;
	template <class U> constexpr FixedAllocator(const FixedAllocator <U, InlineSize>&) {}
	template<class U> struct rebind { using other = FixedAllocator<U, InlineSize>; };
	T* allocate(std::size_t size) {
		if (size + offset_ < InlineSize) {
			T* Data = &element[offset_];
			offset_ += size;
			return Data;
		}
		throw std::bad_alloc();
	}
	void deallocate(T* Data, std::size_t size) {
		if (size > offset_)
			throw std::bad_alloc();
		else
			offset_ -= size;
	}
	size_t offset_ = 0;
	T element[InlineSize];
};

int main() {
	std::vector<int, HeapAllocator<int>> heapVector(8);
	heapVector.push_back(42);
    
	std::vector<int, FixedAllocator<int, 10>> fixedVector(8);
    
    std::list<int, HeapAllocator<int>> heapList;		//list无法使用FixedAllocator，因为其元素的内存不连续
	heapList.push_back(5);
	heapList.push_back(8);
	heapList.push_back(9);
	heapList.remove(8);	
    
	return 0;
}
```

#### 对比

|                  | STL                                         | UE              |
| ---------------- | ------------------------------------------- | --------------- |
| 数据指针存储位置 | 存储在容器中                                | 存储在Allocator |
| Allocator的分配  | 新增内存的分配                              | 内存的重分配    |
| 内存是否连续     | 不一定（像std::array，std::vector这样才有） | 一定            |

通过代码，很容易就能看出为什么UE的容器比 STL 性能更优越的原因：UE保证了容器内存的连续性，然后大量使用栈分配来避免堆分配。相比之下，STL中只有vector拥有这种机制，UE这样实现容器，虽然在管理上略有瑕疵，但可以很大程度地增加数据缓存的命中率。

### 需要做什么？

确定好malloc和allocator之后，主要需要完成的是特定应用场景的优化，其中包括但不限于以下内容：

- 为特定应用场景实现memory_resouce
- 在特定场景使用最优的容器，由于STL的容器类型有限，可考虑接入Boost库来弥补这部分空缺（侵入式(Intrusive)容器、定长(Fixed)容器能极大程度的优化内存使用）

## 总结

- 底层使用三方内存管理框架替换operator new/delete进行内存分配
- 使用EASTL扩展容器库，尽量使用栈空间分配的Fixed容器

## 参考资料

[[UE4\] Memory Allocationについて - Qiita](https://qiita.com/EGJ-Yutaro_Sawada/items/4983d0ebfa945611d324)

[UE4内存分配器概述 - 可可西 - 博客园](https://www.cnblogs.com/kekec/p/12012537.html)

[UE4 Gamedev Guide - Allocators malloc](https://ikrima.dev/ue4guide/engine-programming/memory/allocators-malloc/)

[游戏引擎开发新感觉！(6) c++17内存管理](https://zhuanlan.zhihu.com/p/96089089)

